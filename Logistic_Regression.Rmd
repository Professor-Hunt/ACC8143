---
title: "Logistic Regression"
description: |
  Introduction to logistic regression
output: 
  distill::distill_article:
    toc: true
    toc_depth: 3
---

# Game Plan

In previous sections, we have seen how to perform linear regression on input data to predict a continuous value. In some cases, however, we wish to predict a categorical value, such as True/False or Yes/No. Traditional regression methods are not optimal for these problems, since this requires the prediction of a discrete and not continuous value. In this section we introduce a technique that simulates linear regression, but with an additional function employed that maps the continuous value predicted by linear regression methods into a probability, or specifically the range \[0,1\] . In this manner, we can apply a threshold to this probability to predict a binary response.

While several functions might be suitable for this transformation, the most popular function is the logit function. Note that some older analyses might reference the probit function. Performing regression by using the logit function is known as logistic regression (the inverse of the logit function is known as the logistic function). The name might seem confusing since technically this algorithm is used to perform classification, but since logistic regression borrows heavily in its approach from linear regression, the descriptive name was maintained. A major benefit of logistic regression is the creation of a parametric model that can be explored to understand why predictions are made, in the same manner as a linear regression model.

In this section, we introduce the logit function and how it can be used to construct a binary model. Next, we introduce logistic regression, and specifically show how logistic regression can be performed. We also introduce several popular performance metrics and show how they can be calculated for binary classification tasks. We demonstrate logistic regression on several data sets, including one that contains categorical features. We also demonstrate how to perform logistic regression. Finally, we discuss topics such as marginal effects and odds ratios, which are concepts that often prove useful in interpreting logistic regression models.

# Formalism

In a binary classification process, we have two possible outcomes, which for the sake of generality, we can label as *Success* or *Failure*. Denoting the probability of these two outcomes as $P(S)$ and $P(F)$ respectively, we can write the probability of success as $P(S)=p$, and the probability of failure as $P(F)=1−p$. Thus, the odds of a successful outcome, which is the ratio of the probability of success to the probability of failure, is given by the following expression:

$$
\textrm{Odds}(S) = \frac{p}{1 - p}
$$

We can extend the framework of *linear regression* to the task of binary classification by employing a mapping between the continuous value predicted by a linear regressor and the probability of an event occurring, which is bounded by the range $[0,1]$. To do this, we need a function that maps the real numbers into this range, which enables a regression onto a set of discrete values (0 or 1) that provides us the binary classification. One popular choice for this function is the *logit* function, while another choice is the *probit* function. The use of these functions for a classification task leads to *logistic regression* or *probit regression*. While we focus in this section on the application of logistic regression for the binary classification task, this approach can be generalized to classify into more than two categories, this more advanced technique is known as [multinomial logistic regression](https://en.wikipedia.org/wiki/Multinomial_logistic_regression).

## Logit Function

The [*logit* function](https://en.wikipedia.org/wiki/Logit) is defined as the logarithm of the odds (i.e, $p/(1−p)$), which is also known as the *log-odds*. Thus, the *logit* function can be written for a probability of success $p$:

$$
\textrm{logit}(p) = \log\left(\frac{p}{1 - p}\right) ,  where  0 \leq p \leq 1
$$

We can invert this relationship to obtain the [*logistic* function](https://en.wikipedia.org/wiki/Logistic_function), which for a parameter $α$ is defined by the following expression:

$$
\textrm{logit}^{-1}(\alpha) = \textrm{logistic}(\alpha) = \frac{1}{1 + \exp{(-\alpha})}
$$

While the logistic function is most commonly used to perform this type of regression, a related function is the [*probit* function](https://en.wikipedia.org/wiki/Probit), which stands for *probability unit* and is sometimes used in lieu of the *logit* function. The *probit* function is defined for a probability of success, pp:

$$
\textrm{probit}(p) = \sqrt{2}erf^{-1}(2p - 1), \ where \ 0 \leq p \leq 1 \, and \ erf \ is \ the \ Error \ Function.
$$

The logit function (and the probit function) is an *S* shaped curve that converts real numbers into a probability. Both the logit and probit functions are related to the *sigmoid* function, but are centered at the origin (0, 0). For the rest of this section, we will only consider the logit function. In the following Code chunk, we plot the **logistic** function, or the inverse of the **logit** function, demonstrating how the real numbers can be mapped into the range $[0,1]$.

```{r logistic1, echo=TRUE}
#compute x y axis
x<-seq(-10,10,.5)
y<-1/(1+exp(-x))

library(ggplot2)
ggplot(data=as.data.frame(cbind(x,y)),aes(x,y))+geom_line(color="lightblue",size=.75)+geom_hline(aes(yintercept=.5),color="black",linetype="dashed") +
  theme_minimal() +
  labs(x=expression(alpha), y=expression(Rho), title='Logistic Function') +
  theme(plot.title = element_text(hjust=0.25, size=15, face='bold'))


```

## Gradient Descent

Given the previously defined *logistic* function, we can develop the formalism of *logistic regression* by first employing a linear regression model to predict a dependent variable from the set of independent features. Second, we apply the logistic function to the dependent variable in the linear regression model to make our binary classification prediction. Thus, if we have the following linear model:

$$y=mx+b$$

The logistic regression model fits the following logistic model:

$$\textrm{logistic}(y) = \frac{1}{1 + \exp(-y)}$$

The generally used cost (or loss) function for logistic regression is the sum of the squared errors between the actual classes and the predicted classes. One of the most popular techniques for finding the minimum of this cost function is to use [*stochastic gradient descent*](https://en.wikipedia.org/wiki/Stochastic_gradient_descent). [Gradient descent](https://en.wikipedia.org/wiki/Gradient_descent) computes the derivate of (or finds the slope of the tangent line to) the cost function at a particular point. This can be used to modify the parameters of our model to move in a direction that is expected to reach the minimum of the cost function. Standard gradient descent computes these corrections by summing up all the contributions from each training data point. In stochastic gradient descent (or **SGD**), however, the corrections are computed for each training point. As a result, SGD often generates a path towards the minimum that is somewhat rambling, but this has the benefit of avoiding local minima and being more robust.

The following Code cell generates a figure to help explain gradient descent. A fictitious cost function is displayed, along with the tangent (or derivative) at a particular point. The arrows specify the direction that the derivative indicates we must move to reach the minimum. The repeated use of arrows signifies how an incremental approach to gradient descent, such as that employed by stochastic gradient descent, might converge to the true minimum of the cost function.

```{r logitgradient,echo=TRUE,message=FALSE,warning=FALSE}
x<-seq(-4,4,length.out=100)
y=x^2

library(ggplot2)
ggplot(data=as.data.frame(cbind(x,y)),aes(x,y))+geom_line(color="lightblue",size=.75)+geom_abline(aes(intercept=-1,slope=2),color="red",linetype="dashed") +xlim(-1,3)+ylim(-.5,10)+geom_point(aes(0,0),pch=4,col="red",size=2,stroke=2)+
  theme_minimal() +
  labs(x=expression(x), y=expression(y), title='Gradient Descent') +
  theme(plot.title = element_text(hjust=0.25, size=15, face='bold'))+ 
  geom_text(x=2.75, y=4, label="Decent")+
  geom_text(x=2.3, y=4, label="Gradient")+
  geom_text(x=0, y=-.5, label="Minimum")


```

```{r gradient, echo=FALSE, include=FALSE}
# Generate random data
x <- runif(500, -4, 4)
y <- x + rnorm(500) + 2.5
# Define the squared error cost function
cost <- function(X, y, theta) {
sum( (X %*% theta - y)^2 ) / (2*length(y))
}
 alpha <- 0.1 # Specify the learning rate
 num_iters <- 1000 # Specify the number of iterations
 cost_history <- rep(0,num_iters) # will be used to store the value of cost function after
# every iteration
 theta_history <- list(num_iters) # will be used to store the value of theta after every
# iteration
 theta <-  c(0,0) # Initial values of theta
 X <- cbind(1,x) # Add a column vector with all values  to be 1 to x so that hypothesis
# function has an intercept
 for (i in 1:num_iters) {
   theta[1] <- theta[1] - alpha * (1/length(y)) * sum(((X%*%theta)- y))
   theta[2] <- theta[2] - alpha * (1/length(y)) * sum(((X%*%theta)- y)*X[,2])
   cost_history[i] <- cost(X, y, theta)
   theta_history[[i]] <- theta
 }
 print(theta)
# Plots the training dataset
 plot(x,y, col=rgb(0.2,0.4,0.6,0.4), main='Linear regression by gradient descent')
# Plots various lines during the course of convergence
 for (i in c(1,3,6,10,14,seq(20,num_iters,by=10))) {
 abline(coef=theta_history[[i]], col=rgb(0.8,0,0,0.3))
 }
 abline(coef=theta, col='blue') # Plots a straight line with intercept as theta[1] and slope
# as theta[2]

```

# Logistic Modeling

Before introducing logistic regression, we first show how the logistic function can be used to model binary response data. For this purpose, we will use data from NASA on the relationship between the outside temperature when the space shuttle was launched, and the occurrence of a thermal failure of an O-ring on a booster rocket. We will use this data to create a predictive model between temperature and thermal failure; note that it is believed that the [failure of an O-ring](https://en.wikipedia.org/wiki/Space_Shuttle_Solid_Rocket_Booster#Challenger_disaster) on a solid rocket booster led to the Challenger disaster.

The actual data we use is hosted at the University of California at Irvine (UCI) machine learning data repository.

```{r getdata,echo=TRUE,eval=FALSE}
# install.packages("devtools")
devtools::install_github("tyluRp/ucimlr")

```

```{r echo=TRUE}
library(dplyr)
#its two datasets...pick the first one in the list
NASA<-ucimlr::challenger[[1]]

knitr::kable(psych::describe(NASA))%>%
    kableExtra::kable_styling("striped")%>%
  kableExtra::scroll_box(width="100%",height="200px")
  
```

------------------------------------------------------------------------

From this summary description we can identify several important points. First, there are 23 instances in this data set. Second, this summary indicates that there are no missing values, since each feature has the same number in the `n` column, and the `min` column always contains a valid number. On the other hand, we notice that the maximum value for the number of thermal distresses is two, not one like we require for a binary classification task, which should be zero or one. Thus, our next step is to determine how many instances have a value of two for the `thermal_distress` feature.

```{r checktarge,echo=TRUE}
table(NASA$thermal_distress)
```

As the output demonstrates, we only have one instance that records more than one thermal distress. At this point we have three options:

1.  delete this instance,

2.  duplicate this instance so that two single failure instances exist in the data set, or

3.  change this instance to report only a single thermal distress.

While any of these options might be valid from an algorithmic perspective, they differ from a modeling perspective. The first option would remove valuable data from our set, which is already small. This would also make our model less predictive since this was an actual failure, and we likely do not want to under predict failures, which could have devastating effects. On the other hand, duplicating this instance would be the same as having two separate launches at the same temperature. This could also be problematic, as it would overemphasize a failure at a given temperature.

As a result, we will instead convert this instance to a single thermal distress. The reason in this case is that this measurement did find an instance of a thermal distress, and we are creating a model between temperature and the probability of a thermal failure.

```{r fixtarget,echo=TRUE}

NASA2<-NASA%>%
  mutate(thermal_distress=ifelse(thermal_distress>1,1,thermal_distress))

table(NASA2$thermal_distress)
```

```{r runlogit, echo=TRUE, message=FALSE, warning=FALSE}

#fit logistic regression model
model <- glm(thermal_distress ~ launch_temp, data=NASA2, family=binomial)

#define new data frame that contains predictor variable
newdata <- data.frame(launch_temp=seq(min(NASA2$launch_temp), max(NASA2$launch_temp),len=500))

#use fitted model to predict values of vs
newdata$thermal_distress = predict(model, newdata, type="response")

#plot logistic regression curve
plot(thermal_distress ~ launch_temp, data=NASA2, col="steelblue")
lines(thermal_distress ~ launch_temp, newdata, lwd=2)


#using ggplot
library(ggplot2)

#plot logistic regression curve
ggplot(NASA2, aes(x=launch_temp, y=thermal_distress)) + 
  geom_point(alpha=.5) +
  stat_smooth(method="glm", se=FALSE, method.args = list(family=binomial))+
  theme_minimal() +
  labs(x="launch temperature", y="thermal distress", title='logistic regression') +
  theme(plot.title = element_text(hjust=0.25, size=15, face='bold'))
```

Given a predictive model such as our computed logit model, we can also predict for new, unseen data. In this case, we can predict the probability of thermal failure for a given temperature. The following Code cell computes and displays these probabilities as a function of temperature. Note, that the temperature at launch during the Challenger disaster was 36 degrees Fahrenheit.

```{r putinvalues, echo=TRUE}

for (i in c(36, 58, 65, 72, 88)){
 
  print(paste(i,round(predict(model,data.frame(launch_temp=i),type="response"),3)))

  }

```

## Logistic Regression

```{r logisticreg, echo=TRUE, warning=FALSE, message=FALSE}
library(caret)
#set the seed :)
set.seed(1)
#get our samples

#lets split the data 60/40
library(caret)
trainIndex <- createDataPartition(NASA2$thermal_distress, p = .6, list = FALSE, times = 1)

#look at the first few
#head(trainIndex)

#grab the data
logisticTrain <- NASA2[ trainIndex,]
logisticTest  <- NASA2[-trainIndex,]


NASA_logistic <- train(
  form = thermal_distress ~ launch_temp,
  data = NASA2,
  trControl = trainControl(method = "cv", number = 10),
  method = "glm",
  family = "binomial"
)

NASA_logistic

summary(NASA_logistic)

NASA_Pred<-predict(NASA_logistic,logisticTest)

NASA_Pred

testpred<-cbind(NASA_Pred,logisticTest)


plot(pROC::roc(testpred$thermal_distress,testpred$NASA_Pred))

title(paste("AUC ",round(pROC::roc(testpred$thermal_distress,testpred$NASA_Pred)$auc,3)))

testpred<-testpred%>%
  mutate(prediction=if_else(NASA_Pred>.5,1,0))

confusionMatrix(factor(testpred$prediction),factor(testpred$thermal_distress),positive = "1")


ConfusionTableR::binary_visualiseR(train_labels = factor(testpred$prediction),
                                   truth_labels= factor(testpred$thermal_distress),
                                   class_label1 = "Thermal Distress", 
                                   class_label2 = "Prediction",
                                   quadrant_col1 = "#5D1725", 
                                   quadrant_col2 = "#777777", 
                                   custom_title = "Logistic Confusion Matrix", 
                                   text_col= "black")


```

# 
Exercise 1

Using the code above:

1.  Try including another feature in the model, such as `leak_check_pressure` or `temporal_order_of_flight`, one at a time. Do either of these features improve the performance?
2.  Discuss at least 3 difference performance measures from the confusion matrix results from number 1.
